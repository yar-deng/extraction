{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e9b13d",
   "metadata": {},
   "source": [
    "#### ETL Pipeline: Extract and Transform\n",
    "#### DSA 2040A - Lab 3 & Lab 4\n",
    "#### Student Name: Yar Deng Kuot\n",
    "#### Student ID: [Your Student ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494a3640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_datasets():\n",
    "    \"\"\"Generate full and incremental datasets.\"\"\"\n",
    "    # Full dataset\n",
    "    full_data = pd.DataFrame({\n",
    "        'order_id': [1001, 1002, 1003, 1004, 1005, 1006, 1003, 1007, 1008, 1009],\n",
    "        'customer_id': ['C001', 'C002', 'C003', 'C004', 'C005', 'C006', 'C003', 'C007', 'C008', 'C009'],\n",
    "        'order_date': ['2023-10-01', '10/15/2023', '2023-11-01', None, '2023-11-05', '2023-11-10', '2023-11-01', '2023/12/01', '2024-01-01', '2024-01-02'],\n",
    "        'quantity': [2, 5, 3, 0, np.nan, 4, 3, 2, 1, 6],\n",
    "        'unit_price': [20.0, 15.5, 25.0, 10.0, 30.0, np.nan, 25.0, 50.0, 22.5, 18.0],\n",
    "        'product_category': ['Electronics', 'Clothing', 'Electronics', 'Books', None, 'Furniture', 'Electronics', 'Books', 'Clothing', 'Electronics']\n",
    "    })\n",
    "\n",
    "    # Incremental dataset\n",
    "    incremental_data = pd.DataFrame({\n",
    "        'order_id': [1010, 1011, 1012],\n",
    "        'customer_id': ['C010', 'C011', 'C012'],\n",
    "        'order_date': ['2024-01-03', '2024/01/04', '2024-01-05'],\n",
    "        'quantity': [3, 2, np.nan],\n",
    "        'unit_price': [40.0, np.nan, 15.0],\n",
    "        'product_category': ['Furniture', 'Electronics', 'Books']\n",
    "    })\n",
    "\n",
    "    # Save raw datasets\n",
    "    full_data.to_csv('raw_full.csv', index=False)\n",
    "    incremental_data.to_csv('raw_incremental.csv', index=False)\n",
    "\n",
    "    return full_data, incremental_data\n",
    "\n",
    "def transform_data(df):\n",
    "    \"\"\"Apply transformations: cleaning, enrichment, and structural changes.\"\"\"\n",
    "    # 1. Cleaning: Handle missing values and remove duplicates\n",
    "    df = df.dropna(subset=['order_date', 'quantity', 'product_category'])\n",
    "    df = df.fillna({'unit_price': df['unit_price'].mean()})\n",
    "    df = df.drop_duplicates(subset=['order_id'])\n",
    "\n",
    "    # 2. Enrichment: Add total_price column\n",
    "    df['total_price'] = df['quantity'] * df['unit_price']\n",
    "\n",
    "    # 3. Structural: Standardize date format and convert data types\n",
    "    df['order_date'] = pd.to_datetime(df['order_date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "    df['quantity'] = df['quantity'].astype(int)\n",
    "    df['unit_price'] = df['unit_price'].astype(float)\n",
    "\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the ETL pipeline.\"\"\"\n",
    "    print(\"Starting ETL Pipeline...\")\n",
    "    \n",
    "    # Extract data\n",
    "    full_data, incremental_data = generate_datasets()\n",
    "    print(\"\\nFull Dataset:\")\n",
    "    print(full_data)\n",
    "    print(\"\\nIncremental Dataset:\")\n",
    "    print(incremental_data)\n",
    "\n",
    "    # Transform full data\n",
    "    transformed_full = transform_data(full_data)\n",
    "    print(\"\\nTransformed Full Dataset:\")\n",
    "    print(transformed_full)\n",
    "    transformed_full.to_csv('transformed_full.csv', index=False)\n",
    "\n",
    "    # Transform incremental data\n",
    "    transformed_incremental = transform_data(incremental_data)\n",
    "    print(\"\\nTransformed Incremental Dataset:\")\n",
    "    print(transformed_incremental)\n",
    "    transformed_incremental.to_csv('transformed_incremental.csv', index=False)\n",
    "\n",
    "    print(\"\\nETL Pipeline completed. Outputs saved as 'transformed_full.csv' and 'transformed_incremental.csv'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750f1f88",
   "metadata": {},
   "source": [
    "#### Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341fc6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Missing Values for ETL Pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_datasets():\n",
    "    \"\"\"Generate full and incremental datasets.\"\"\"\n",
    "    # Full dataset\n",
    "    full_data = pd.DataFrame({\n",
    "        'order_id': [1001, 1002, 1003, 1004, 1005, 1006, 1003, 1007, 1008, 1009],\n",
    "        'customer_id': ['C001', 'C002', 'C003', 'C004', 'C005', 'C006', 'C003', 'C007', 'C008', 'C009'],\n",
    "        'order_date': ['2023-10-01', '10/15/2023', '2023-11-01', None, '2023-11-05', '2023-11-10', '2023-11-01', '2023/12/01', '2024-01-01', '2024-01-02'],\n",
    "        'quantity': [2, 5, 3, 0, np.nan, 4, 3, 2, 1, 6],\n",
    "        'unit_price': [20.0, 15.5, 25.0, 10.0, 30.0, np.nan, 25.0, 50.0, 22.5, 18.0],\n",
    "        'product_category': ['Electronics', 'Clothing', 'Electronics', 'Books', None, 'Furniture', 'Electronics', 'Books', 'Clothing', 'Electronics']\n",
    "    })\n",
    "\n",
    "    # Incremental dataset\n",
    "    incremental_data = pd.DataFrame({\n",
    "        'order_id': [1010, 1011, 1012],\n",
    "        'customer_id': ['C010', 'C011', 'C012'],\n",
    "        'order_date': ['2024-01-03', '2024/01/04', '2024-01-05'],\n",
    "        'quantity': [3, 2, np.nan],\n",
    "        'unit_price': [40.0, np.nan, 15.0],\n",
    "        'product_category': ['Furniture', 'Electronics', 'Books']\n",
    "    })\n",
    "\n",
    "    return full_data, incremental_data\n",
    "\n",
    "def check_missing_values(df, dataset_name):\n",
    "    \"\"\"Check and summarize missing values in the dataset.\"\"\"\n",
    "    print(f\"\\nChecking Missing Values in {dataset_name} Dataset:\")\n",
    "    \n",
    "    # Total missing values per column\n",
    "    missing_counts = df.isna().sum()\n",
    "    print(\"\\nMissing Values per Column:\")\n",
    "    print(missing_counts)\n",
    "    \n",
    "    # Percentage of missing values per column\n",
    "    missing_percent = (df.isna().sum() / len(df)) * 100\n",
    "    print(\"\\nPercentage of Missing Values per Column:\")\n",
    "    print(missing_percent)\n",
    "    \n",
    "    # Rows with any missing values\n",
    "    missing_rows = df[df.isna().any(axis=1)]\n",
    "    print(\"\\nRows with Missing Values:\")\n",
    "    print(missing_rows)\n",
    "    \n",
    "    # Summary statistics\n",
    "    total_missing = df.isna().sum().sum()\n",
    "    print(f\"\\nTotal Missing Values in {dataset_name} Dataset: {total_missing}\")\n",
    "    \n",
    "    # Save missing values summary to a file\n",
    "    with open(f'missing_values_{dataset_name.lower()}.txt', 'w') as f:\n",
    "        f.write(f\"Missing Values Summary for {dataset_name} Dataset\\n\\n\")\n",
    "        f.write(\"Missing Values per Column:\\n\")\n",
    "        f.write(missing_counts.to_string())\n",
    "        f.write(\"\\n\\nPercentage of Missing Values per Column:\\n\")\n",
    "        f.write(missing_percent.to_string())\n",
    "        f.write(\"\\n\\nTotal Missing Values: {}\\n\".format(total_missing))\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to check missing values.\"\"\"\n",
    "    print(\"Starting Missing Values Analysis...\")\n",
    "    \n",
    "    # Load datasets\n",
    "    full_data, incremental_data = generate_datasets()\n",
    "    \n",
    "    # Check missing values for both datasets\n",
    "    check_missing_values(full_data, \"Full\")\n",
    "    check_missing_values(incremental_data, \"Incremental\")\n",
    "    \n",
    "    print(\"\\nMissing values analysis completed. Summaries saved as 'missing_values_full.txt' and 'missing_values_incremental.txt'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
