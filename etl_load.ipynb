{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05470e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading full data...\n",
      "Saved full data to loaded_data\\full_data.parquet\n",
      "Saved full data to SQLite database: loaded_data\\full_data.db\n",
      "Loading incremental data...\n",
      "Saved incremental data to loaded_data\\incremental_data.parquet\n",
      "Saved incremental data to SQLite database: loaded_data\\incremental_data.db\n",
      "\n",
      "Verifying loaded data...\n",
      "Full Data SQLite Preview:\n",
      "   order_id customer_id  order_date  quantity  unit_price product_category  \\\n",
      "0      1001        C001  2023-10-01         2   20.000000      Electronics   \n",
      "1      1002        C002  2023-10-15         5   15.500000         Clothing   \n",
      "2      1003        C003  2023-11-01         3   25.000000      Electronics   \n",
      "3      1006        C006  2023-11-10         4   25.142857        Furniture   \n",
      "4      1007        C007  2023-12-01         2   50.000000            Books   \n",
      "\n",
      "   total_price  \n",
      "0    40.000000  \n",
      "1    77.500000  \n",
      "2    75.000000  \n",
      "3   100.571429  \n",
      "4   100.000000  \n",
      "\n",
      "Incremental Data SQLite Preview:\n",
      "   order_id customer_id  order_date  quantity  unit_price product_category  \\\n",
      "0      1010        C010  2024-01-03         3        40.0        Furniture   \n",
      "1      1011        C011  2024-01-04         2        40.0      Electronics   \n",
      "\n",
      "   total_price  \n",
      "0        120.0  \n",
      "1         80.0  \n",
      "\n",
      "Full Data Parquet Preview:\n",
      "   order_id customer_id  order_date  quantity  unit_price product_category  \\\n",
      "0      1001        C001  2023-10-01         2   20.000000      Electronics   \n",
      "1      1002        C002  2023-10-15         5   15.500000         Clothing   \n",
      "2      1003        C003  2023-11-01         3   25.000000      Electronics   \n",
      "3      1006        C006  2023-11-10         4   25.142857        Furniture   \n",
      "4      1007        C007  2023-12-01         2   50.000000            Books   \n",
      "\n",
      "   total_price  \n",
      "0    40.000000  \n",
      "1    77.500000  \n",
      "2    75.000000  \n",
      "3   100.571429  \n",
      "4   100.000000  \n",
      "\n",
      "Incremental Data Parquet Preview:\n",
      "   order_id customer_id  order_date  quantity  unit_price product_category  \\\n",
      "0      1010        C010  2024-01-03         3        40.0        Furniture   \n",
      "1      1011        C011  2024-01-04         2        40.0      Electronics   \n",
      "\n",
      "   total_price  \n",
      "0        120.0  \n",
      "1         80.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "def setup_paths():\n",
    "    \"\"\"Set up file paths and create output directory.\"\"\"\n",
    "    FULL_CSV_PATH = 'transformed_full.csv'\n",
    "    INCREMENTAL_CSV_PATH = 'transformed_incremental.csv'\n",
    "    OUTPUT_DIR = 'loaded_data'\n",
    "    FULL_DB_PATH = os.path.join(OUTPUT_DIR, 'full_data.db')\n",
    "    INCREMENTAL_DB_PATH = os.path.join(OUTPUT_DIR, 'incremental_data.db')\n",
    "    FULL_PARQUET_PATH = os.path.join(OUTPUT_DIR, 'full_data.parquet')\n",
    "    INCREMENTAL_PARQUET_PATH = os.path.join(OUTPUT_DIR, 'incremental_data.parquet')\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    # Verify input files exist\n",
    "    if not os.path.exists(FULL_CSV_PATH):\n",
    "        raise FileNotFoundError(f'{FULL_CSV_PATH} not found. Ensure Lab 4 output is available.')\n",
    "    if not os.path.exists(INCREMENTAL_CSV_PATH):\n",
    "        raise FileNotFoundError(f'{INCREMENTAL_CSV_PATH} not found. Ensure Lab 4 output is available.')\n",
    "    \n",
    "    return (FULL_CSV_PATH, INCREMENTAL_CSV_PATH, \n",
    "            FULL_DB_PATH, INCREMENTAL_DB_PATH, \n",
    "            FULL_PARQUET_PATH, INCREMENTAL_PARQUET_PATH)\n",
    "\n",
    "def load_full_data(full_csv_path, full_db_path, full_parquet_path):\n",
    "    \"\"\"Load transformed_full.csv into SQLite and Parquet.\"\"\"\n",
    "    # Load full CSV into DataFrame\n",
    "    full_df = pd.read_csv(full_csv_path)\n",
    "    \n",
    "    # Save to Parquet\n",
    "    full_df.to_parquet(full_parquet_path, index=False)\n",
    "    print(f'Saved full data to {full_parquet_path}')\n",
    "    \n",
    "    # Save to SQLite with defined schema\n",
    "    conn = sqlite3.connect(full_db_path)\n",
    "    full_df.to_sql('full_data', conn, if_exists='replace', index=False, dtype={\n",
    "        'id': 'INTEGER PRIMARY KEY',\n",
    "        'customer_name': 'TEXT',\n",
    "        'product': 'TEXT',\n",
    "        'quantity': 'INTEGER',\n",
    "        'unit_price': 'REAL',\n",
    "        'total_price': 'REAL',\n",
    "        'order_date': 'TEXT'\n",
    "    })\n",
    "    conn.close()\n",
    "    print(f'Saved full data to SQLite database: {full_db_path}')\n",
    "\n",
    "def load_incremental_data(incremental_csv_path, incremental_db_path, incremental_parquet_path):\n",
    "    \"\"\"Load transformed_incremental.csv into SQLite and Parquet.\"\"\"\n",
    "    # Load incremental CSV into DataFrame\n",
    "    incremental_df = pd.read_csv(incremental_csv_path)\n",
    "    \n",
    "    # Save to Parquet\n",
    "    incremental_df.to_parquet(incremental_parquet_path, index=False)\n",
    "    print(f'Saved incremental data to {incremental_parquet_path}')\n",
    "    \n",
    "    # Save to SQLite with defined schema\n",
    "    conn = sqlite3.connect(incremental_db_path)\n",
    "    incremental_df.to_sql('incremental_data', conn, if_exists='replace', index=False, dtype={\n",
    "        'id': 'INTEGER PRIMARY KEY',\n",
    "        'customer_name': 'TEXT',\n",
    "        'product': 'TEXT',\n",
    "        'quantity': 'INTEGER',\n",
    "        'unit_price': 'REAL',\n",
    "        'total_price': 'REAL',\n",
    "        'order_date': 'TEXT'\n",
    "    })\n",
    "    conn.close()\n",
    "    print(f'Saved incremental data to SQLite database: {incremental_db_path}')\n",
    "\n",
    "def verify_loaded_data(full_db_path, incremental_db_path, full_parquet_path, incremental_parquet_path):\n",
    "    \"\"\"Verify loaded data by previewing SQLite tables and Parquet files.\"\"\"\n",
    "    # Verify SQLite full_data\n",
    "    conn = sqlite3.connect(full_db_path)\n",
    "    full_query = pd.read_sql_query('SELECT * FROM full_data LIMIT 5', conn)\n",
    "    print('Full Data SQLite Preview:')\n",
    "    print(full_query)\n",
    "    conn.close()\n",
    "    \n",
    "    # Verify SQLite incremental_data\n",
    "    conn = sqlite3.connect(incremental_db_path)\n",
    "    incremental_query = pd.read_sql_query('SELECT * FROM incremental_data LIMIT 5', conn)\n",
    "    print('\\nIncremental Data SQLite Preview:')\n",
    "    print(incremental_query)\n",
    "    conn.close()\n",
    "    \n",
    "    # Verify Parquet full_data\n",
    "    full_parquet_df = pd.read_parquet(full_parquet_path)\n",
    "    print('\\nFull Data Parquet Preview:')\n",
    "    print(full_parquet_df.head())\n",
    "    \n",
    "    # Verify Parquet incremental_data\n",
    "    incremental_parquet_df = pd.read_parquet(incremental_parquet_path)\n",
    "    print('\\nIncremental Data Parquet Preview:')\n",
    "    print(incremental_parquet_df.head())\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to execute the ETL load process.\"\"\"\n",
    "    # Setup paths\n",
    "    (FULL_CSV_PATH, INCREMENTAL_CSV_PATH, \n",
    "     FULL_DB_PATH, INCREMENTAL_DB_PATH, \n",
    "     FULL_PARQUET_PATH, INCREMENTAL_PARQUET_PATH) = setup_paths()\n",
    "    \n",
    "    # Load data\n",
    "    print(\"Loading full data...\")\n",
    "    load_full_data(FULL_CSV_PATH, FULL_DB_PATH, FULL_PARQUET_PATH)\n",
    "    print(\"Loading incremental data...\")\n",
    "    load_incremental_data(INCREMENTAL_CSV_PATH, INCREMENTAL_DB_PATH, INCREMENTAL_PARQUET_PATH)\n",
    "    \n",
    "    # Verify loaded data\n",
    "    print(\"\\nVerifying loaded data...\")\n",
    "    verify_loaded_data(FULL_DB_PATH, INCREMENTAL_DB_PATH, FULL_PARQUET_PATH, INCREMENTAL_PARQUET_PATH)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
